{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "099f6c7d-b825-49a0-ae34-b13854399ff0",
   "metadata": {},
   "source": [
    "# Сравнение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "120fb0f5-52e6-437f-a546-003a1931b929",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Загрузка набора данных и занижение тестового до 452 примеров по каждому классу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0293ecdf-5e61-4985-b684-01488dbb2216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка модели и наборов данных\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#тренировочный набор\n",
    "train_df = pd.read_csv('Preprocessed_train_data_selection.csv', low_memory=True)\n",
    "#тестовый набор\n",
    "test_df = pd.read_csv('Preprocessed_test_data_selection.csv', low_memory=True)\n",
    "\n",
    "y_train, x_train = train_df[\"Label\"], train_df.drop(columns=[\"Label\"]).copy()\n",
    "\n",
    "y_test, x_test = test_df[\"Label\"], test_df.drop(columns=[\"Label\"]).copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "65d5b8ee-5706-4750-b8ee-cc5fe09ee697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({0: 452, 1: 452, 2: 452, 3: 452, 4: 452, 5: 452, 6: 452, 7: 452, 8: 452, 9: 452, 10: 452})\n"
     ]
    }
   ],
   "source": [
    "# применение undersampling к тестовой выборке\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "#занижаю классы тестового набора до количество примеров самого наименьшего (452)\n",
    "\n",
    "rus = RandomUnderSampler(random_state=42)\n",
    "\n",
    "#автоматическое преобразование всех классов к количеству самого маленького\n",
    "x_test_balanced, y_test_balanced = rus.fit_resample(x_test, y_test)\n",
    "\n",
    "\n",
    "print(Counter(y_test_balanced))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0f38db-f7f7-4d04-8a11-86137af09f1a",
   "metadata": {},
   "source": [
    "## Сравнение моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d35e2e9-d4e9-4a80-826c-2030aa01f189",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Инициализация моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13058a9d-2b03-497c-bac8-31b0e0acd04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training logistic Regression ...\n",
      "logistic Regression / accuracy: 0.4562 / f1-score: 0.3669\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.63      0.33       452\n",
      "           1       0.00      0.00      0.00       452\n",
      "           2       0.45      0.89      0.60       452\n",
      "           3       0.76      0.75      0.76       452\n",
      "           4       0.85      0.87      0.86       452\n",
      "           5       0.59      0.71      0.65       452\n",
      "           6       0.73      0.17      0.27       452\n",
      "           7       0.00      0.00      0.00       452\n",
      "           8       0.40      1.00      0.57       452\n",
      "           9       0.04      0.00      0.00       452\n",
      "          10       0.00      0.00      0.00       452\n",
      "\n",
      "    accuracy                           0.46      4972\n",
      "   macro avg       0.37      0.46      0.37      4972\n",
      "weighted avg       0.37      0.46      0.37      4972\n",
      "\n",
      "training Decision tree ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MeizekiN\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\MeizekiN\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\MeizekiN\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree / accuracy: 0.9366 / f1-score: 0.9382\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.98      0.76       452\n",
      "           1       0.99      0.63      0.77       452\n",
      "           2       1.00      1.00      1.00       452\n",
      "           3       1.00      0.99      1.00       452\n",
      "           4       0.98      1.00      0.99       452\n",
      "           5       1.00      0.99      0.99       452\n",
      "           6       1.00      1.00      1.00       452\n",
      "           7       1.00      1.00      1.00       452\n",
      "           8       1.00      1.00      1.00       452\n",
      "           9       0.93      0.83      0.88       452\n",
      "          10       0.99      0.88      0.93       452\n",
      "\n",
      "    accuracy                           0.94      4972\n",
      "   macro avg       0.95      0.94      0.94      4972\n",
      "weighted avg       0.95      0.94      0.94      4972\n",
      "\n",
      "training Random forest - default Params ...\n",
      "Random forest - default Params / accuracy: 0.9785 / f1-score: 0.9786\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.98      0.94       452\n",
      "           1       0.99      0.95      0.97       452\n",
      "           2       1.00      1.00      1.00       452\n",
      "           3       1.00      1.00      1.00       452\n",
      "           4       0.99      1.00      0.99       452\n",
      "           5       1.00      0.99      1.00       452\n",
      "           6       1.00      1.00      1.00       452\n",
      "           7       1.00      1.00      1.00       452\n",
      "           8       1.00      1.00      1.00       452\n",
      "           9       0.91      0.96      0.93       452\n",
      "          10       0.99      0.89      0.94       452\n",
      "\n",
      "    accuracy                           0.98      4972\n",
      "   macro avg       0.98      0.98      0.98      4972\n",
      "weighted avg       0.98      0.98      0.98      4972\n",
      "\n",
      "training Random Forest - Optimized Params ...\n",
      "Random Forest - Optimized Params / accuracy: 0.9387 / f1-score: 0.9388\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.96      0.79       452\n",
      "           1       0.99      0.65      0.79       452\n",
      "           2       1.00      1.00      1.00       452\n",
      "           3       1.00      1.00      1.00       452\n",
      "           4       0.97      1.00      0.99       452\n",
      "           5       1.00      0.99      1.00       452\n",
      "           6       1.00      1.00      1.00       452\n",
      "           7       1.00      1.00      1.00       452\n",
      "           8       1.00      1.00      1.00       452\n",
      "           9       0.93      0.82      0.87       452\n",
      "          10       0.89      0.91      0.90       452\n",
      "\n",
      "    accuracy                           0.94      4972\n",
      "   macro avg       0.95      0.94      0.94      4972\n",
      "weighted avg       0.95      0.94      0.94      4972\n",
      "\n",
      "training Gradient Boosting ...\n",
      "Gradient Boosting / accuracy: 0.9399 / f1-score: 0.9405\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.96      0.78       452\n",
      "           1       0.99      0.65      0.78       452\n",
      "           2       1.00      1.00      1.00       452\n",
      "           3       1.00      1.00      1.00       452\n",
      "           4       0.97      1.00      0.99       452\n",
      "           5       1.00      0.98      0.99       452\n",
      "           6       1.00      1.00      1.00       452\n",
      "           7       1.00      1.00      1.00       452\n",
      "           8       1.00      1.00      1.00       452\n",
      "           9       0.92      0.87      0.90       452\n",
      "          10       0.95      0.89      0.92       452\n",
      "\n",
      "    accuracy                           0.94      4972\n",
      "   macro avg       0.95      0.94      0.94      4972\n",
      "weighted avg       0.95      0.94      0.94      4972\n",
      "\n",
      "training XGBoost ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MeizekiN\\anaconda3\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [04:31:31] WARNING: D:\\bld\\xgboost-split_1737531311373\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost / accuracy: 0.9397 / f1-score: 0.9407\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.97      0.77       452\n",
      "           1       0.99      0.64      0.78       452\n",
      "           2       1.00      1.00      1.00       452\n",
      "           3       1.00      1.00      1.00       452\n",
      "           4       0.98      1.00      0.99       452\n",
      "           5       1.00      0.99      1.00       452\n",
      "           6       1.00      1.00      1.00       452\n",
      "           7       1.00      1.00      1.00       452\n",
      "           8       1.00      1.00      1.00       452\n",
      "           9       0.93      0.84      0.88       452\n",
      "          10       0.97      0.89      0.93       452\n",
      "\n",
      "    accuracy                           0.94      4972\n",
      "   macro avg       0.96      0.94      0.94      4972\n",
      "weighted avg       0.96      0.94      0.94      4972\n",
      "\n",
      "training LightGBM ...\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.011332 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 6490\n",
      "[LightGBM] [Info] Number of data points in the train set: 459617, number of used features: 33\n",
      "[LightGBM] [Info] Start training from score -1.525223\n",
      "[LightGBM] [Info] Start training from score -3.827808\n",
      "[LightGBM] [Info] Start training from score -1.634848\n",
      "[LightGBM] [Info] Start training from score -3.827808\n",
      "[LightGBM] [Info] Start training from score -1.525223\n",
      "[LightGBM] [Info] Start training from score -3.827808\n",
      "[LightGBM] [Info] Start training from score -3.827808\n",
      "[LightGBM] [Info] Start training from score -3.827808\n",
      "[LightGBM] [Info] Start training from score -1.525223\n",
      "[LightGBM] [Info] Start training from score -3.827808\n",
      "[LightGBM] [Info] Start training from score -3.827808\n",
      "LightGBM / accuracy: 0.4789 / f1-score: 0.4908\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.17      0.83      0.28       452\n",
      "           1       0.40      0.29      0.33       452\n",
      "           2       0.97      0.83      0.89       452\n",
      "           3       0.65      0.27      0.38       452\n",
      "           4       0.80      0.70      0.75       452\n",
      "           5       0.67      0.12      0.20       452\n",
      "           6       0.64      0.44      0.52       452\n",
      "           7       0.31      0.05      0.08       452\n",
      "           8       0.77      0.84      0.80       452\n",
      "           9       0.74      0.30      0.43       452\n",
      "          10       0.93      0.61      0.74       452\n",
      "\n",
      "    accuracy                           0.48      4972\n",
      "   macro avg       0.64      0.48      0.49      4972\n",
      "weighted avg       0.64      0.48      0.49      4972\n",
      "\n",
      "training SVM ...\n",
      "SVM / accuracy: 0.5145 / f1-score: 0.4887\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.34      0.27       452\n",
      "           1       0.00      0.00      0.00       452\n",
      "           2       0.43      0.64      0.52       452\n",
      "           3       0.89      0.93      0.91       452\n",
      "           4       0.96      0.81      0.88       452\n",
      "           5       0.82      0.79      0.81       452\n",
      "           6       0.97      0.35      0.52       452\n",
      "           7       0.72      0.49      0.58       452\n",
      "           8       0.26      0.99      0.42       452\n",
      "           9       1.00      0.32      0.49       452\n",
      "          10       0.00      0.00      0.00       452\n",
      "\n",
      "    accuracy                           0.51      4972\n",
      "   macro avg       0.57      0.51      0.49      4972\n",
      "weighted avg       0.57      0.51      0.49      4972\n",
      "\n",
      "training KNN ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MeizekiN\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\MeizekiN\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\MeizekiN\\anaconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\MeizekiN\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] Не удается найти указанный файл\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\MeizekiN\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\MeizekiN\\anaconda3\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\MeizekiN\\anaconda3\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Users\\MeizekiN\\anaconda3\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN / accuracy: 0.8481 / f1-score: 0.8562\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.43      0.96      0.59       452\n",
      "           1       0.99      0.62      0.77       452\n",
      "           2       0.77      0.98      0.87       452\n",
      "           3       1.00      0.99      0.99       452\n",
      "           4       0.96      0.77      0.85       452\n",
      "           5       0.99      0.97      0.98       452\n",
      "           6       0.99      0.96      0.97       452\n",
      "           7       0.99      0.99      0.99       452\n",
      "           8       0.98      0.96      0.97       452\n",
      "           9       1.00      0.52      0.68       452\n",
      "          10       0.99      0.61      0.76       452\n",
      "\n",
      "    accuracy                           0.85      4972\n",
      "   macro avg       0.92      0.85      0.86      4972\n",
      "weighted avg       0.92      0.85      0.86      4972\n",
      "\n",
      "training Naive Bayes ...\n",
      "Naive Bayes / accuracy: 0.3580 / f1-score: 0.3329\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.04      0.00      0.00       452\n",
      "           1       0.85      0.26      0.40       452\n",
      "           2       0.27      0.19      0.22       452\n",
      "           3       0.43      0.37      0.39       452\n",
      "           4       0.25      0.20      0.22       452\n",
      "           5       0.96      0.55      0.70       452\n",
      "           6       0.60      0.47      0.52       452\n",
      "           7       0.17      0.51      0.26       452\n",
      "           8       0.00      0.00      0.00       452\n",
      "           9       0.26      0.51      0.35       452\n",
      "          10       0.44      0.89      0.59       452\n",
      "\n",
      "    accuracy                           0.36      4972\n",
      "   macro avg       0.39      0.36      0.33      4972\n",
      "weighted avg       0.39      0.36      0.33      4972\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "#Загрузка созданных моделей с дефотными и подобранными гиперпараметрами\n",
    "with open('model_rfc_default.pkl', 'rb') as file:\n",
    "    rfc_def_model = pickle.load(file)\n",
    "\n",
    "with open('model_rfc_optimized.pkl', 'rb') as file:\n",
    "    rfc_opt_model = pickle.load(file)\n",
    "\n",
    "\n",
    "all_models = {\n",
    "    \"logistic Regression\": LogisticRegression(max_iter=1000, n_jobs=-1),\n",
    "    \"Decision tree\": DecisionTreeClassifier(),\n",
    "    \"Random forest - default Params\": rfc_def_model,\n",
    "    \"Random Forest - Optimized Params\": rfc_opt_model,\n",
    "    \"Gradient Boosting\": GradientBoostingClassifier(),\n",
    "    \"XGBoost\": XGBClassifier(use_label_encoder=False, eval_metric='logloss', n_jobs=-1),\n",
    "    \"LightGBM\": LGBMClassifier(n_jobs=-1),\n",
    "    \"SVM\": SVC(),\n",
    "    \"KNN\": KNeighborsClassifier(n_jobs=-1),\n",
    "    \"Naive Bayes\": GaussianNB()\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for name, model in all_models.items():\n",
    "    print(f'training {name} ...')\n",
    "    \n",
    "    start_time = time.time()\n",
    "    model.fit(x_train, y_train)\n",
    "    end_time = time.time()\n",
    "\n",
    "    duration_time = end_time - start_time\n",
    "    \n",
    "    y_pred = model.predict(x_test_balanced)\n",
    "\n",
    "    acc = accuracy_score(y_test_balanced, y_pred)\n",
    "    f1 = f1_score(y_test_balanced, y_pred, average='macro')\n",
    "    \n",
    "    results.append([name, acc, f1, duration_time])\n",
    "    print(f'{name} / accuracy: {acc:.4f} / f1-score: {f1:.4f}')\n",
    "    print(classification_report(y_test_balanced, y_pred))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55582ac8-9d4f-4026-a26d-fa3b07429d13",
   "metadata": {},
   "source": [
    "## Сравнение моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5e62c01a-80c4-490a-a881-c4c29eeced86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              Model  Accuracy  Macro_F1         Time\n",
      "2    Random forest - default Params  0.978479  0.978550     7.574879\n",
      "5                           XGBoost  0.939662  0.940663     8.824879\n",
      "4                 Gradient Boosting  0.939863  0.940515  1096.577016\n",
      "3  Random Forest - Optimized Params  0.938656  0.938797    49.943717\n",
      "1                     Decision tree  0.936645  0.938156     3.356018\n",
      "8                               KNN  0.848150  0.856230     0.066000\n",
      "6                          LightGBM  0.478882  0.490797     4.376038\n",
      "7                               SVM  0.514481  0.488726  7336.722956\n",
      "0               logistic Regression  0.456154  0.366942   125.983646\n",
      "9                       Naive Bayes  0.358005  0.332884     0.163003\n"
     ]
    }
   ],
   "source": [
    "result_models_df = pd.DataFrame(results, columns=[\"Model\", \"Accuracy\", \"Macro_F1\", \"Time\"])\n",
    "print(result_models_df.sort_values(by=\"Macro_F1\", ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4168ed3e-0f81-4086-a987-d5838ef70aa4",
   "metadata": {},
   "source": [
    "## Сохранение результата сравнения в файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a293a408-3405-49e7-b880-b16215f281db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сравнение моделей успешно сохранено\n"
     ]
    }
   ],
   "source": [
    "result_models_df.to_csv(\"Models_compare.csv\")\n",
    "print(\"Сравнение моделей успешно сохранено\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602752fa-0bd8-47ef-a31b-cc14d89e8c2d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
